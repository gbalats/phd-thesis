Static program analysis is a vast field with broad uses; an umbrella
term for many different methodologies (%
\begin{inparablank}
  \item Hoare logic
    \cite{journals/cacm/Hoare69,floyd1967assigning,lics:2002/Reynolds,csl/OHearnRY01},
  \item model checking
    \cite{icalp/EmersonC80,lop/ClarkeE81,toplas/ClarkeES86,programm/QueilleS82},
  \item symbolic execution
    \cite{journals/cacm/King76,journals/tse/Howden77,conf/kbse/PasareanuR10,Boyer:1975:SFS:390016.808445},
  \item abstract interpretation
    \cite{popl/CousotC77,journals/jlp/CousotC92,journals/logcom/CousotC92},
  \item data-flow analysis
    \cite{popl/Kildall73,books/daglib/0030999,books/mk/Muchnick1997,journals/acta/KamU77,popl/RepsHS95,books/ph/SharirP81},
\end{inparablank}
and so on), that aim to automatically obtain an
understanding of a program's behavior, without running it. Nowadays,
one form or another of static analysis can be found in many different
contexts: compilers, IDEs, editors, linters, or even dedicated static
analysis tools or frameworks. The ends of a static analysis tool are
equally diversified, ranging from bug finding and program
verification to optimization, or even aided program comprehension.

Along with static analysis tools, the programming languages have
evolved as well, becoming more high-level throughout the years,
introducing many layers of abstraction, before eventually translating
the program to the machine's native opcodes. High-level languages are
appealing because they are easier to program in, and maintain. Less
programming effort (e.g., in terms of lines of code) is needed to
express some computation. Virtual machines have even abstracted away
the platform where the code will run. Instead, programs of managed
languages are translated to machine code for some \emph{virtual
  machine}, and hence may run on any platform that provides a backend
that emulates this virtual machine.

Software has evolved too. Complex design patterns, immense libraries,
frameworks implementing inversion of control, over-involved build
tools, and many other complicacies pose significant challenges to
program understanding.

As one would expect, static analyses have struggled to keep up with
the ever-increasing complexity of software and the programming
languages it is written in; the very task of automated program
understanding has become daunting, yet even more valuable.

The most promising and powerful of existing static analysis techniques
rely on the creation of some \emph{abstract memory model} of the
program. What objects will the memory contain, at some state of
execution? What will their structure be like?  A faithful abstract
representation of the actual memory is, however, a demanding task; its
precision often detrimental to the value of whatever the static
analysis is aiming to eventually compute (be it the identification of
complex bug patterns or the opportunities for effective
optimizations).

In this dissertation we argue that there is \emph{implicit structural
  information} in the program, about the memory it will allocate, that
can improve the quality of the abstract memory model constructed by
static analysis. This structural information is not readily available,
but may be recovered via inference, primarily by tracking the use of
types in the program.

We provide a number of techniques that recover such
lost memory structure, in two different settings:%
\begin{inparaenum}[(1)]
\item in C/C++ programs, as a typical case of low-level code, where
  the program's memory structure is often lost due to specific
  programming idioms and the inherent low-level nature of the
  language, and
\item in Java programs, where despite the high-level nature of the
  language, structural information may be lost for \emph{partial
    programs} (i.e., libraries or any programs that lack some of their
  parts), which, in the form of Java Archives (JARs), constitute the
  main distributable code entity of this managed language.
\end{inparaenum}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
