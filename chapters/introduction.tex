Static program analysis is a vast field with broad uses; an umbrella
term for many different methodologies (%
\begin{inparablank}
  \item Hoare logic
    \cite{journals/cacm/Hoare69,floyd1967assigning,lics:2002/Reynolds,csl/OHearnRY01},
  \item model checking
    \cite{icalp/EmersonC80,lop/ClarkeE81,toplas/ClarkeES86,programm/QueilleS82},
  \item symbolic execution
    \cite{journals/cacm/King76,journals/tse/Howden77,conf/kbse/PasareanuR10,Boyer:1975:SFS:390016.808445},
  \item abstract interpretation
    \cite{popl/CousotC77,journals/jlp/CousotC92,journals/logcom/CousotC92},
  \item data-flow analysis
    \cite{popl/Kildall73,books/daglib/0030999,books/mk/Muchnick1997,journals/acta/KamU77,popl/RepsHS95,books/ph/SharirP81},
\end{inparablank}
and so on), that aim to automatically obtain an
understanding of a program's behavior, without running it. Nowadays,
one form or another of static analysis can be found in many different
contexts: compilers, IDEs, editors, linters, or even dedicated static
analysis tools or frameworks. The ends of a static analysis tool are
equally diversified, ranging from bug finding and program
verification to optimization, or even aided program comprehension.

Along with static analysis tools, the programming languages have
evolved as well, becoming more high-level throughout the years,
introducing many layers of abstraction, before eventually translating
the program to the machine's native opcodes. High-level languages are
appealing because they are easier to program in, and maintain. Less
programming effort (e.g., in terms of lines of code) is needed to
express some computation. Virtual machines have even abstracted away
the platform where the code will run. Instead, programs of managed
languages are translated to machine code for some \emph{virtual
  machine}, and hence may run on any platform that provides a backend
that emulates this virtual machine.

Software has evolved too. Complex design patterns, immense libraries,
frameworks implementing inversion of control, over-involved build
tools, and many other complicacies pose significant challenges to
program understanding.

As one would expect, static analyses have struggled to keep up with
the ever-increasing complexity of software and the programming
languages it is written in; the very task of automated program
understanding has become daunting, yet even more valuable.

The most promising and powerful of existing static analysis techniques
rely on the creation of some \emph{abstract memory model} of the
program. What objects will the memory contain, at some state of
execution? What will their structure be like?  A faithful abstract
representation of the actual memory is, however, a demanding task; its
precision often detrimental to the value of whatever the static
analysis is aiming to eventually compute (be it the identification of
complex bug patterns or the opportunities for effective
optimizations).

In this dissertation we argue that there is \emph{implicit structural
  information} in the program, about the memory it will allocate, that
can improve the quality of the abstract memory model constructed by
static analysis. This structural information is not readily available,
but may be recovered via inference, primarily by tracking the use of
types in the program.

We provide a number of techniques that recover such
lost memory structure, in two different settings:%
\begin{inparaenum}[(1)]
\item in C/C++ programs, as a typical case of low-level code, where
  the program's memory structure is often lost due to specific
  programming idioms and the inherent low-level nature of the
  language, and
\item in Java programs, where despite the high-level nature of the
  language, structural information may be lost for \emph{partial
    programs} (i.e., libraries or any programs that lack some of their
  parts), which, in the form of Java Archives (JARs), constitute the
  main distributable code entity of this managed language.
\end{inparaenum}


\section{Impact}

\subsection{Scientific}

A weakly-typed language, such as C or C++, exposes pointers as numeric
values and allows the programmer to perform arbitrary arithmetic on
them. These \emph{pointer arithmetic} capabilities can be used to
bypass the language's type system. Also, objects may be allocated on
memory without any local information about their intended type, at the
allocation site. In fact, most heap-allocating routines (e.g.,
\code{malloc()}) return just an array of bytes. These allocations,
while in this \emph{untyped state}, flow to various other instructions
and may be even stored to type-agnostic raw pointer
variables. Normally, when such an allocation was intended to create an
object of type \(T\), a cast instruction or an implicit conversion
will be used prior to any other instruction that expected an object of
this specific type.

In the case of C/C++ programs, the main scientific contributions of
this work comprise a number of techniques that enhance pointer
analysis precision by ``dynamically'' associating and maintaining type
information for all abstract objects in memory.

\emph{Pointer analysis} is a static program analysis that determines
the values of pointer variables or expressions. For each pointer, it
computes a set of memory allocations that the pointer may point to. We
refer to this as the \emph{points-to set} of a variable. Since
computing an exact model of memory is undecidable, a static analysis
needs to sacrifice performance for computability. Thus, the memory
allocations of pointer analysis are mere abstractions; a single
allocation may represent many concrete objects at some program
execution. One such popular abstraction represents memory objects by
their allocation sites. Hence, any number of concrete objects
allocated at the same instruction correspond to a single abstract
object.

By the term ``dynamically'', we mean that any object-type association
is performed simultaneously with the pointer analysis itself (in a
manner similar to \emph{on-the-fly} call-graph construction). The
pointer analysis uses the inferred types of abstract objects to
produce new points-to facts or filter spurious inferences due to type
incompatibility. The points-to sets, on the other hand, drive the
creation of new object-type associations that may again alter the
produced points-to sets, and so on---all partaking in an
interdependent recursive cycle of computation.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
